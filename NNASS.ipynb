{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NNASS",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeEi5vj9uIcI"
      },
      "source": [
        "#Get the datasets\n",
        "!wget -q https://github.com/jomokojomoko/CISCASSIGNMENT/raw/main/Video_games_esrb_rating.csv\n",
        "!wget -q https://github.com/jomokojomoko/CISCASSIGNMENT/raw/main/test_esrb.csv\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8riFWhuE4V3n",
        "outputId": "173374e1-a6b6-4f08-a82b-9a5ef48623cf"
      },
      "source": [
        "#Process the datasets into training and testing\n",
        "import pandas as pd\n",
        "import csv\n",
        "from sklearn import preprocessing\n",
        "from keras.utils import np_utils\n",
        "#Get testing and training datasets\n",
        "xy_train_df = pd.read_csv('Video_games_esrb_rating.csv',error_bad_lines=False)\n",
        "test=pd.read_csv('test_esrb.csv',error_bad_lines=False)\n",
        "#Get X sets\n",
        "xtrain=xy_train_df.drop(columns=['title','esrb_rating'])\n",
        "xtest=test.drop(columns=['title','esrb_rating'])\n",
        "#Get Y sets\n",
        "ytrain=xy_train_df['esrb_rating']\n",
        "ytest=test['esrb_rating']\n",
        "print(ytrain)\n",
        "#One Hot Encoding\n",
        "le=preprocessing.LabelEncoder()\n",
        "le.fit(ytrain)\n",
        "ytrain=le.transform(ytrain)\n",
        "ytest=le.transform(ytest)\n",
        "yc=ytest\n",
        "ytest=np_utils.to_categorical(ytest)\n",
        "ytrain=np_utils.to_categorical(ytrain)\n",
        "print(ytrain)\n",
        "print(yc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0        E\n",
            "1       ET\n",
            "2        M\n",
            "3       ET\n",
            "4        T\n",
            "        ..\n",
            "1890     M\n",
            "1891     T\n",
            "1892     E\n",
            "1893     T\n",
            "1894     E\n",
            "Name: esrb_rating, Length: 1895, dtype: object\n",
            "[[1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " ...\n",
            " [1. 0. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [1. 0. 0. 0.]]\n",
            "[3 0 3 0 1 2 2 1 0 3 3 3 1 3 3 2 2 3 0 1 3 1 1 3 1 1 0 3 2 1 3 1 1 3 3 3 2\n",
            " 1 0 3 3 3 0 2 0 0 3 1 1 1 3 3 2 1 2 1 3 3 2 3 0 2 1 0 2 1 3 0 0 0 0 1 3 1\n",
            " 3 1 3 2 0 0 3 3 3 1 0 2 2 3 1 1 0 1 3 3 3 0 1 1 1 3 0 0 3 2 2 0 2 3 3 3 3\n",
            " 3 1 3 0 3 3 1 3 0 3 3 1 0 2 3 0 1 1 3 1 3 2 3 0 3 3 0 3 3 0 3 3 3 2 3 2 3\n",
            " 1 1 1 0 1 3 0 0 0 2 3 3 1 1 1 0 2 0 2 0 1 3 2 1 3 3 2 0 2 3 1 2 2 3 3 3 0\n",
            " 3 1 2 1 3 0 0 1 1 3 3 2 3 0 3 0 0 3 3 3 1 3 0 1 2 3 3 0 3 2 0 3 0 3 1 3 3\n",
            " 2 0 3 0 3 0 2 2 3 2 2 3 2 0 3 1 0 0 0 1 1 1 2 2 1 2 1 3 3 1 0 2 1 3 0 3 1\n",
            " 3 1 1 2 2 1 3 3 3 3 2 0 3 0 2 3 1 1 0 2 1 2 1 0 3 3 0 3 3 1 3 3 2 1 1 3 2\n",
            " 1 1 1 1 3 1 0 3 1 3 3 0 0 0 3 3 3 0 3 3 0 3 1 0 2 3 1 3 2 0 0 2 1 3 2 2 3\n",
            " 3 3 1 2 3 0 3 2 3 3 2 3 0 1 2 2 3 3 1 1 3 0 2 2 3 3 2 1 1 0 1 1 3 3 0 3 3\n",
            " 3 0 3 1 0 0 1 3 2 0 1 1 0 0 3 1 0 1 1 1 3 2 1 3 3 0 1 3 3 0 1 3 2 3 2 1 1\n",
            " 3 3 3 1 3 1 1 3 0 0 0 1 3 1 3 1 2 0 2 3 3 1 3 1 0 0 3 1 2 0 1 1 3 3 2 3 2\n",
            " 3 2 0 1 3 2 3 0 2 2 3 1 1 3 3 2 3 0 1 3 0 3 3 2 1 1 2 0 1 2 3 2 1 2 1 3 1\n",
            " 3 3 2 2 3 1 0 0 1 1 0 2 1 3 2 2 2 3 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLM4KyxZNqBn",
        "outputId": "1005b0ff-34b2-4886-9c3f-ad4857bc3681"
      },
      "source": [
        "#Neural Network Model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, Dropout, Input\n",
        "\n",
        "#Function to build a model\n",
        "def build():\n",
        "    #Defindes the shape of the input\n",
        "    #The shape is 32 arttibutes\n",
        "    img_in = Input(shape=(32))\n",
        "\n",
        "    #Activation layers\n",
        "    fc1 = Dense(200)(img_in) \n",
        "    fc2 = Dense(200,activation=\"relu\")(fc1)\n",
        "    fc3 = Dense(200)(fc2)\n",
        "    fc4 = Dense(200,activation=\"relu\")(fc3)\n",
        "    fc5 = Dense(200)(fc4)\n",
        "    #final layor using softmax activation function  with 4 ouput\n",
        "    output = Dense(4, activation = 'softmax')(fc5)\n",
        "    #Creates a keras model defining the input, and output\n",
        "    model = tf.keras.Model(inputs=img_in, outputs=output)\n",
        "    return model\n",
        "\n",
        "\n",
        "model = build()\n",
        "#Configuring the model for training\n",
        "#Uses the Adam model for optimization\n",
        "#Calculates loss with categorical cross entropy\n",
        "#The metrics used for validation in this model is accuracy\n",
        "model.compile(\n",
        "        loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 32)]              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 200)               6600      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 200)               40200     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 200)               40200     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 200)               40200     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 200)               40200     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 4)                 804       \n",
            "=================================================================\n",
            "Total params: 168,204\n",
            "Trainable params: 168,204\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUCBPdlKfHtM",
        "outputId": "96e3960e-168f-4d6c-f09f-0884b9f74c11"
      },
      "source": [
        "epochs = 10\n",
        "batch_size = 64\n",
        "\n",
        "#Fitting the model with the training set\n",
        "#Fitting the models batch size\n",
        "#10 epochs\n",
        "#0.3 of the data will be used to validate the model\n",
        "history = model.fit(x = xtrain,\n",
        "                    y = ytrain,\n",
        "                    batch_size = batch_size,\n",
        "                    validation_split=0.3,\n",
        "                    epochs=epochs\n",
        "                    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 1.0154 - accuracy: 0.5763 - val_loss: 0.3849 - val_accuracy: 0.8699\n",
            "Epoch 2/10\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.4070 - accuracy: 0.8357 - val_loss: 0.3381 - val_accuracy: 0.8682\n",
            "Epoch 3/10\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3592 - accuracy: 0.8461 - val_loss: 0.2956 - val_accuracy: 0.8910\n",
            "Epoch 4/10\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3059 - accuracy: 0.8828 - val_loss: 0.2896 - val_accuracy: 0.8893\n",
            "Epoch 5/10\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3045 - accuracy: 0.8790 - val_loss: 0.3081 - val_accuracy: 0.8787\n",
            "Epoch 6/10\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3244 - accuracy: 0.8579 - val_loss: 0.2894 - val_accuracy: 0.8735\n",
            "Epoch 7/10\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.2864 - accuracy: 0.8868 - val_loss: 0.2875 - val_accuracy: 0.8963\n",
            "Epoch 8/10\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.2548 - accuracy: 0.9022 - val_loss: 0.2949 - val_accuracy: 0.8928\n",
            "Epoch 9/10\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.2378 - accuracy: 0.9038 - val_loss: 0.2941 - val_accuracy: 0.8998\n",
            "Epoch 10/10\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.2537 - accuracy: 0.9054 - val_loss: 0.3372 - val_accuracy: 0.8489\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPikpwt5wEx4",
        "outputId": "80faa7a3-721e-4e0c-adcf-f0deeb010e17"
      },
      "source": [
        "#Evaluate the model\n",
        "print(\"Evaluate on test data\")\n",
        "results = model.evaluate(xtest, ytest, batch_size=64)\n",
        "print(\"test loss, test acc:\", results)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluate on test data\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.8500\n",
            "test loss, test acc: [0.47647467255592346, 0.8500000238418579]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QujaNXBdhIgg",
        "outputId": "a7c1b0f2-5b3d-42a1-bbcb-652d903d0a61"
      },
      "source": [
        "#Get the confusion matrix\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "ypred=model.predict(xtest)\n",
        "rounded=np.argmax(ypred, axis=-1)\n",
        "confusion = confusion_matrix(yc,rounded)\n",
        "print(confusion)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 95   4   0   1]\n",
            " [  4 112   1   9]\n",
            " [  0   0  72  18]\n",
            " [  2  21  15 146]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}